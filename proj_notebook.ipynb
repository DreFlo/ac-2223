{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b77a989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sb\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64228076",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f0b5f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\ficheiros_competicao_dev\\\\client.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nh/n1r42zln7wb03k411lj0rwdc0000gn/T/ipykernel_7464/1848684309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.\\\\ficheiros_competicao_dev\\\\client.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccount_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.\\\\ficheiros_competicao_dev\\\\account.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrans_dev_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.\\\\ficheiros_competicao_dev\\\\trans_dev.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\ficheiros_competicao_dev\\\\client.csv'"
     ]
    }
   ],
   "source": [
    "client_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\client.csv', sep=';', low_memory=False)\n",
    "\n",
    "account_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\account.csv', sep=';', low_memory=False)\n",
    "\n",
    "trans_dev_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\trans_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "loan_dev_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\loan_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "card_dev_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\card_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "disp_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\disp.csv', sep=';', low_memory=False)\n",
    "\n",
    "district_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\district.csv', sep=';', low_memory=False, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9e2a5",
   "metadata": {},
   "source": [
    "# Domain Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7ae94",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919f623",
   "metadata": {},
   "source": [
    "### End User Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fec16d",
   "metadata": {},
   "source": [
    "The end user requires a system to determine which clients are and are not capable of paying of the loans they seek to make of the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ac790",
   "metadata": {},
   "source": [
    "### Business Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab537c",
   "metadata": {},
   "source": [
    "In this problem the positive case is a client that cannot pay a loan. The business goal is to create a system to:\n",
    "- Reduce the amount of loan attributions to clients who will default on the loan\n",
    "- Mantain the amount of loan attributions to clients who can fulfill the loan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c43d54",
   "metadata": {},
   "source": [
    "### Data Mining Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2fe04",
   "metadata": {},
   "source": [
    "From the business goals we can determine that the goal of the model is to avoid granting a loan to a client who cannot pay it back, minimize false negatives so we must optimze for recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14629deb",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b39b6",
   "metadata": {},
   "source": [
    "### Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loan_dev_df[loan_dev_df['status'] == 1]) / len(loan_dev_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bffac",
   "metadata": {},
   "source": [
    "Around 86% of loans in the dataset have been payed off, so accuracy is not the best measure to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.violinplot(x='status', y='amount', data=loan_dev_df, hue='status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e77896",
   "metadata": {},
   "source": [
    "We can see a larger amount of the loans over 100,000 are not payed off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cff7c1",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872a7dd",
   "metadata": {},
   "source": [
    "## Whitespace Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.rename(columns=lambda x: x.strip(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9b061",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621fb2ba",
   "metadata": {},
   "source": [
    "### Acount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dabfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658737de",
   "metadata": {},
   "source": [
    "No missing values on **account_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0fc54",
   "metadata": {},
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a489f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc9910",
   "metadata": {},
   "source": [
    "No missing values on **client_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f132f47",
   "metadata": {},
   "source": [
    "### Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604bab8",
   "metadata": {},
   "source": [
    "No missing values on **loan_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a883a",
   "metadata": {},
   "source": [
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb13ea7",
   "metadata": {},
   "source": [
    "There are missing values on **trans_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8547af9",
   "metadata": {},
   "source": [
    "#### Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146488ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trans_dev_df[trans_dev_df['operation'].isnull()]) / len(trans_dev_df['operation']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea626bc",
   "metadata": {},
   "source": [
    "There is a significant number of null values in the operations column. These will be replaced by 'N/A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319834df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a7072",
   "metadata": {},
   "source": [
    "#### K Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40416d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04ffb5",
   "metadata": {},
   "source": [
    "There are many empty string values. It is assumed these mean the transaction type wasn't registered and they will be treated the same as null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227136db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_values_k_symbol(k):\n",
    "    if isinstance(k, float):\n",
    "        return'N/A'\n",
    "    elif isinstance(k, str) and k.strip() == '':\n",
    "        return 'N/A'\n",
    "    else:\n",
    "        return k\n",
    "\n",
    "trans_dev_df['k_symbol'] = trans_dev_df['k_symbol'].apply(remove_empty_values_k_symbol)\n",
    "\n",
    "trans_dev_df['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fb775",
   "metadata": {},
   "source": [
    "#### Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabff64f",
   "metadata": {},
   "source": [
    "There aren't any empty strings. Null values will be replaced by unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a73363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac452db3",
   "metadata": {},
   "source": [
    "#### Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100f80b",
   "metadata": {},
   "source": [
    "There are many transactions to an account **0**. This will be treated as a transaction to an unknown account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db79109",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0929f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbf6d8",
   "metadata": {},
   "source": [
    "### Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5dd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c04f77",
   "metadata": {},
   "source": [
    "There are no missing values in **card_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d443a",
   "metadata": {},
   "source": [
    "### Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60b69a",
   "metadata": {},
   "source": [
    "There are no missing values in **disp_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243df78",
   "metadata": {},
   "source": [
    "### District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc72143",
   "metadata": {},
   "source": [
    "There are missing values in **district_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df[district_df['unemploymant rate \\'95'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab2484",
   "metadata": {},
   "source": [
    "Both null values com from the district of Jesenik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454aab6c",
   "metadata": {},
   "source": [
    "We will replace the null values by finding the mean values for the region in 1995 and 1996 and inferring the 1995 values for Jesenik from the 1996 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1646876",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_rate_96_mean = district_df[district_df['region'] == 'north Moravia']['unemploymant rate \\'96'].median()\n",
    "\n",
    "unemp_rate_95_mean = district_df[district_df['region'] == 'north Moravia']['unemploymant rate \\'95'].median()\n",
    "\n",
    "unemp_rate_96_jes = district_df.iloc[68]['unemploymant rate \\'96']\n",
    "\n",
    "predicted_unemp_rate_95_jes = (unemp_rate_95_mean/unemp_rate_96_mean) * unemp_rate_96_jes\n",
    "\n",
    "district_df['unemploymant rate \\'95'].fillna(predicted_unemp_rate_95_jes, inplace=True)\n",
    "\n",
    "crimes_96_mean = district_df[district_df['region'] == 'north Moravia']['no. of commited crimes \\'96'].median()\n",
    "\n",
    "crimes_95_mean = district_df[district_df['region'] == 'north Moravia']['no. of commited crimes \\'95'].median()\n",
    "\n",
    "crimes_96_jes = district_df.iloc[68]['no. of commited crimes \\'96']\n",
    "\n",
    "predicted_crimes_95_jes = (crimes_95_mean/crimes_96_mean) * crimes_96_jes\n",
    "\n",
    "district_df['no. of commited crimes \\'95'].fillna(predicted_crimes_95_jes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845097b1",
   "metadata": {},
   "source": [
    "## Date Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format birth number to date (DD-MM-YY) <- may need to change formatting for algorithms\n",
    "def get_formatted_date(date_number):\n",
    "    date_number_string = str(date_number)\n",
    "    return date_number_string[4:6] + '/' + str(int(date_number_string[2:4]) % 50) + '/' + '19' + date_number_string[0:2]\n",
    "\n",
    "# Get client sex from birth number (MM > 50 => sex == 'F')\n",
    "def get_client_sex_from_birth_number(date_number):\n",
    "    return 'F' if int(str(date_number)[2:4]) >= 51 else 'M'\n",
    "\n",
    "def get_season_from_Date(date_string):\n",
    "    date_string_str = str(date_string)\n",
    "    day = int(date_string_str[8:10])\n",
    "    month = int(date_string_str[5:7])\n",
    "    year = int(date_string_str[0:4])\n",
    "\n",
    "    winterStart = datetime.datetime(year, 12, 22)\n",
    "    springStart = datetime.datetime(year, 3, 20)\n",
    "    summerStart = datetime.datetime(year, 6, 21)\n",
    "    autumnStart = datetime.datetime(year, 9, 22)\n",
    "\n",
    "    if ((month <= 3 and day <= 20) or (month >= 12 and day > 22)):\n",
    "        return \"winter\"\n",
    "    elif (date_string < summerStart):\n",
    "        return \"spring\"\n",
    "    elif (date_string < autumnStart) : \n",
    "        return \"summer\"\n",
    "    elif (date_string < winterStart) :\n",
    "        return \"autumn\"\n",
    "\n",
    "    return \"FAILEDSEASON\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60dafe",
   "metadata": {},
   "source": [
    "## Format dates and determine client sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format client birthday and determine sex\n",
    "\n",
    "client_df['birthday'] = pd.to_datetime(client_df['birth_number'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "client_df['sex'] = client_df['birth_number'].apply(get_client_sex_from_birth_number)\n",
    "\n",
    "client_df = client_df.drop(columns=['birth_number'])\n",
    "\n",
    "# Format other dates\n",
    "\n",
    "account_df['acc_creation_date'] = pd.to_datetime(account_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "account_df = account_df.drop(columns=['date'])\n",
    "\n",
    "trans_dev_df['trans_date'] = pd.to_datetime(trans_dev_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "trans_dev_df = trans_dev_df.drop(columns=['date'])\n",
    "\n",
    "loan_dev_df['date'] = pd.to_datetime(loan_dev_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "card_dev_df['issued'] = pd.to_datetime(card_dev_df['issued'].apply(get_formatted_date), infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275a899",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2ea80",
   "metadata": {},
   "source": [
    "Data must all be displayed in one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb260c",
   "metadata": {},
   "source": [
    "## Join Account and Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = account_df.merge(disp_df, on='account_id', how='inner', suffixes=['', '_disp'])\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'type': 'account_type',\n",
    "    'frequency': 'issuance_freq'\n",
    "}, inplace=True)\n",
    "\n",
    "# Determine if account is shared or not\n",
    "owner_number_account = joined_df['account_id'].value_counts()\n",
    "\n",
    "joined_df['shared'] = joined_df.apply(lambda row: 1 if owner_number_account[row['account_id']] > 1 else 0, axis=1)\n",
    "\n",
    "# Drop rows with disponents so there are no duplicated account rows\n",
    "joined_df.drop(joined_df[joined_df['account_type'] == 'DISPONENT'].index, inplace=True)\n",
    "\n",
    "# Drop account_type and disp_id column\n",
    "joined_df.drop(columns=['account_type'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e16e6",
   "metadata": {},
   "source": [
    "## Join Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(client_df, on='client_id', how='left', suffixes=['', '_client'])\n",
    "\n",
    "joined_df.drop(columns=['client_id'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9cfbd",
   "metadata": {},
   "source": [
    "## Join District"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d613f10",
   "metadata": {},
   "source": [
    "There are currently two District ids in the dataset for each row. We are going to join on the client's district id since we surmise this information will be more relevant to wheter they pay off the loan or not than the district the account was registered on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbae4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(district_df, left_on='district_id_client', right_on='code', how='inner', suffixes=['', '_district'])\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'code': 'district_code',\n",
    "    'name': 'district_name'\n",
    "}, inplace=True)\n",
    "\n",
    "joined_df.drop(columns=['district_id', 'district_id_client'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e1e50",
   "metadata": {},
   "source": [
    "## Join Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(loan_dev_df, on='account_id', how='right', suffixes=['', '_loan'])\n",
    "\n",
    "joined_df.drop(columns=['loan_id'], inplace=True)\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'date': 'loan_date'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add seasons\n",
    "joined_df['season_on_loan'] = joined_df['loan_date'].apply(get_season_from_Date)\n",
    "\n",
    "joined_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbedc9",
   "metadata": {},
   "source": [
    "## Determine account owner age on loan request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['age_on_loan_request'] = joined_df.apply(lambda row: (row['loan_date'] - row['birthday'])/np.timedelta64(1, 'Y'), axis=1)\n",
    "\n",
    "joined_df.drop(columns=['birthday'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5217a",
   "metadata": {},
   "source": [
    "## Join Cards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00e278",
   "metadata": {},
   "source": [
    "There are a lot of clients without cards so simply joining the datasets would result in a large amount of null values. Instead we will record the card score attached to each account giving more weight to *classic* and *gold* cards. This is done beacause to have access to better credit cards the client must have a history of making and paying of loans in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_disp_df = card_dev_df.merge(disp_df, on='disp_id', how='inner', suffixes=['_card', '_disp'])\n",
    "\n",
    "cards_per_user_df = card_disp_df.groupby(['account_id', 'type_card']).size().unstack(fill_value=0)\n",
    "\n",
    "joined_df = joined_df.merge(cards_per_user_df, on='account_id', how='left', suffixes=['', ''])\n",
    "\n",
    "joined_df.fillna(0, inplace=True)\n",
    "\n",
    "joined_df['card_score'] = (joined_df['junior'] + joined_df['classic'] * 3 + joined_df['gold'] * 10).astype(int)\n",
    "\n",
    "joined_df.drop(columns=['junior', 'classic', 'gold'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961cce3",
   "metadata": {},
   "source": [
    "## Join Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12db79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "account_balance_df = trans_dev_df[['account_id', 'balance', 'trans_date']]\n",
    "\n",
    "def find_balance_at_date(joined_df_row):\n",
    "    # Get all balance information for account\n",
    "    account_balances = account_balance_df[account_balance_df['account_id'] == joined_df_row['account_id']]\n",
    "    \n",
    "    # Get balance at loan date\n",
    "    account_balances_at_loan_date = account_balances.copy()\n",
    "\n",
    "    account_balances_at_loan_date['days_since_trans'] = account_balances_at_loan_date.apply(lambda row: (joined_df_row['loan_date'] - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_at_loan_date = account_balances_at_loan_date[account_balances_at_loan_date['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_at_loan_date = account_balances_at_loan_date[account_balances_at_loan_date['days_since_trans'] == account_balances_at_loan_date['days_since_trans'].min()]\n",
    "\n",
    "\n",
    "    # Get balance three months before loan date\n",
    "    three_months_ago = joined_df_row['loan_date'] - relativedelta(months=3)\n",
    "\n",
    "    account_balances_three_months_ago = account_balances.copy()\n",
    "\n",
    "    account_balances_three_months_ago['days_since_trans'] = account_balances_three_months_ago.apply(lambda row: (three_months_ago - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_three_months_ago = account_balances_three_months_ago[account_balances_three_months_ago['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_three_months_ago = account_balances_three_months_ago[account_balances_three_months_ago['days_since_trans'] == account_balances_three_months_ago['days_since_trans'].min()]\n",
    "\n",
    "    # Get balance six months before loan date\n",
    "    six_months_ago = joined_df_row['loan_date'] - relativedelta(months=6)\n",
    "\n",
    "    account_balances_six_months_ago = account_balances.copy()\n",
    "\n",
    "    account_balances_six_months_ago['days_since_trans'] = account_balances_six_months_ago.apply(lambda row: (six_months_ago - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_six_months_ago = account_balances_six_months_ago[account_balances_six_months_ago['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_six_months_ago = account_balances_six_months_ago[account_balances_six_months_ago['days_since_trans'] == account_balances_six_months_ago['days_since_trans'].min()]\n",
    "\n",
    "\n",
    "    joined_df_row['balance_at_loan'] = account_balances_at_loan_date.iloc[0]['balance'] if len(account_balances_at_loan_date.index) >= 1 else 0\n",
    "    joined_df_row['balance_three_months_before'] = account_balances_three_months_ago.iloc[0]['balance'] if len(account_balances_three_months_ago.index) >= 1 else 0\n",
    "    joined_df_row['balance_six_months_before'] = account_balances_six_months_ago.iloc[0]['balance'] if len(account_balances_six_months_ago.index) >= 1 else 0\n",
    "\n",
    "    return joined_df_row[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']]\n",
    "\n",
    "joined_df[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']] = joined_df.apply(find_balance_at_date, axis=1)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77bf28",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1141782",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.describe()[['no. of commited crimes \\'95', 'age_on_loan_request', 'duration', 'payments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216db2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(joined_df, x='no. of commited crimes \\'95')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_IQR(df):\n",
    "\n",
    "   q1=df.quantile(0.25)\n",
    "\n",
    "   q3=df.quantile(0.75)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "\n",
    "   return outliers\n",
    "\n",
    "outliers = find_outliers_IQR(joined_df['no. of commited crimes \\'95'])\n",
    "\n",
    "print(\"number of outliers: \" + str(len(outliers)))\n",
    "\n",
    "print(\"max outlier value: \" + str(outliers.max()))\n",
    "\n",
    "print(\"min outlier value: \" + str(outliers.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b0a20",
   "metadata": {},
   "source": [
    "### Remove underage users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2de0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "underage = joined_df.loc[joined_df['age_on_loan_request']<18]\n",
    "\n",
    "joined_df.drop(underage.index, inplace=True)\n",
    "\n",
    "joined_df.describe()[['age_on_loan_request']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e776f",
   "metadata": {},
   "source": [
    "# Split into age brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd931db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(joined_df, x='age_on_loan_request')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_bracket(age):\n",
    "    if age >= 18 and age <= 24:\n",
    "        return '18-24'\n",
    "    elif age >= 25 and age <= 34:\n",
    "        return '25-34'\n",
    "    elif age>= 35 and age <= 44:\n",
    "        return '35-44'\n",
    "    elif age >= 45 and age <= 54:\n",
    "        return '45-54'\n",
    "    elif age >= 55 and age <= 64:\n",
    "        return '55-64'\n",
    "    elif age >= 65:\n",
    "        return '65+'\n",
    "\n",
    "joined_df['age_bracket'] = joined_df['age_on_loan_request'].apply(get_age_bracket)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8bb4b",
   "metadata": {},
   "source": [
    "## Set Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['shared'] = joined_df['shared'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['status'] = joined_df['status'].apply(lambda x: 1 if x == 1 else 0)\n",
    "joined_df['status'] = joined_df['status'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad78fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop(columns=['district_name', 'account_id', 'disp_id', 'age_on_loan_request'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa91567",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'shared',\n",
    "    'no. of municipalities with inhabitants < 499',\n",
    "    'no. of municipalities with inhabitants 500-1999',\n",
    "    'no. of municipalities with inhabitants 2000-9999',\n",
    "    'no. of municipalities with inhabitants >10000', \n",
    "    'no. of cities',\n",
    "    'ratio of urban inhabitants', \n",
    "    'average salary', \n",
    "    'unemploymant rate \\'96', \n",
    "    'no. of enterpreneurs per 1000 inhabitants',\n",
    "    'amount', \n",
    "    'duration', \n",
    "    'payments',\n",
    "    'age_bracket',\n",
    "    'card_score', \n",
    "    'balance_at_loan',\n",
    "    'balance_three_months_before',\n",
    "    'balance_six_months_before',\n",
    "    'issuance_freq',\n",
    "    'sex', \n",
    "    'district_code',\n",
    "    'region',\n",
    "    'season_on_loan'\n",
    "    ]\n",
    "    \n",
    "target = 'status'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add662f",
   "metadata": {},
   "source": [
    "### Remove Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25064b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['sex', 'region', 'issuance_freq', 'season_on_loan', 'age_bracket']\n",
    "\n",
    "joined_df[cat] = joined_df[cat].astype('category')\n",
    "\n",
    "joined_df[cat] = joined_df[cat].apply(lambda x : x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = joined_df[features].corr(method='spearman')\n",
    "\n",
    "mask = np.zeros_like(corr_matrix, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title('Correlation Matrix', fontsize=25)\n",
    "_ = sb.heatmap(corr_matrix, mask=mask, cmap='coolwarm', annot=True, fmt='.2f', linewidths=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c642ed3",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "def do_anova(cols, k=\"all\"):\n",
    "    best_features = SelectKBest(score_func=f_classif, k=k)\n",
    "    df_cut = joined_df[cols]\n",
    "    fit = best_features.fit(df_cut, joined_df[\"status\"])\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(df_cut.columns)\n",
    "\n",
    "    # concat 2 dataFrame for better visualization\n",
    "    feature_score = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    feature_score.columns = [\"Features\", \"Score\"]\n",
    "    ret = feature_score.sort_values(by=\"Score\", ascending=False)\n",
    "    return ret.head(k) if k != \"all\" else ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf78fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_anova(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'shared',\n",
    "    'balance_at_loan',\n",
    "    'payments',\n",
    "    'amount',\n",
    "    'balance_six_months_before',\n",
    "    'balance_three_months_before',\n",
    "    'no. of municipalities with inhabitants < 499',\n",
    "    'no. of cities',\n",
    "    'season_on_loan',\n",
    "    'age_bracket'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d1a1f",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68af59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joined_df[selected_features]\n",
    "y = joined_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3578526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92998bf2",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Some of the algorithms we plan on using (KNN and SVM) require the data to be standardized. To do so, we used a StandardScaler from SciKit Learn's preprocessing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30978fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sk.preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361601b6",
   "metadata": {},
   "source": [
    "## Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad928ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a02687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf, \n",
    "                   feature_names=selected_features,  \n",
    "                   class_names=target,\n",
    "                   filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdefd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': [3, 5, 10], \n",
    "    'n_estimators' : [100, 300],\n",
    "    'max_depth': [3, 5, 15, 25],\n",
    "    'max_features': [3, 5, 10, 20]\n",
    "}\n",
    "\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8678511",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_smote, y_train_smote)\n",
    "y_pred_smote = rfc.predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a148f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43480e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bee58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = [5, 10, 15, 20]\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "leaf_size=[10,20,30,40,50,60]\n",
    "p=[1,2,3,4,5] \n",
    "algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "\n",
    "parameter_grid = param_grid = dict(n_neighbors = k_range, weights = weight_options,algorithm= algorithm ,leaf_size = leaf_size , p =p)\n",
    "\n",
    "knn = sk.neighbors.KNeighborsClassifier()\n",
    "\n",
    "grid = sk.model_selection.GridSearchCV(knn, param_grid, cv = 10, scoring = 'accuracy')\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "print(sk.metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: \",sk.metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", sk.metrics.precision_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
