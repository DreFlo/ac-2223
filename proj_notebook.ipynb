{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77a989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sb\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64228076",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = pd.read_csv('./ficheiros_competicao_dev/client.csv', sep=';', low_memory=False)\n",
    "\n",
    "account_df = pd.read_csv('./ficheiros_competicao_dev/account.csv', sep=';', low_memory=False)\n",
    "\n",
    "trans_dev_df = pd.read_csv('./ficheiros_competicao_dev/trans_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "loan_dev_df = pd.read_csv('./ficheiros_competicao_dev/loan_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "card_dev_df = pd.read_csv('./ficheiros_competicao_dev/card_dev.csv', sep=';', low_memory=False)\n",
    "\n",
    "disp_df = pd.read_csv('./ficheiros_competicao_dev/disp.csv', sep=';', low_memory=False)\n",
    "\n",
    "district_df = pd.read_csv('./ficheiros_competicao_dev/district.csv', sep=';', low_memory=False, na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9e2a5",
   "metadata": {},
   "source": [
    "# Domain Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7ae94",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919f623",
   "metadata": {},
   "source": [
    "### End User Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fec16d",
   "metadata": {},
   "source": [
    "The end user requires a system to determine which clients are and are not capable of paying of the loans they seek to make of the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ac790",
   "metadata": {},
   "source": [
    "### Business Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab537c",
   "metadata": {},
   "source": [
    "In this problem the positive case is a client that cannot pay a loan. The business goal is to create a system to:\n",
    "- Reduce the amount of loan attributions to clients who will default on the loan\n",
    "- Mantain the amount of loan attributions to clients who can fulfill the loan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c43d54",
   "metadata": {},
   "source": [
    "### Data Mining Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2fe04",
   "metadata": {},
   "source": [
    "From the business goals we can determine that the goal of the model is to avoid granting a loan to a client who cannot pay it back, minimize false negatives so we must optimze for recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14629deb",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"account\", account_df.describe(include='all'), \"\\n\")\n",
    "print(\"client\", client_df.describe(include='all'), \"\\n\")\n",
    "print(\"disposition\", disp_df.describe(include='all'), \"\\n\")\n",
    "print(\"district\", district_df.describe(include='all'), \"\\n\")\n",
    "print(\"card_train\", card_dev_df.describe(include='all'), \"\\n\")\n",
    "print(\"loan_train\", loan_dev_df.describe(include='all'), \"\\n\")\n",
    "print(\"trans_train\", trans_dev_df.describe(include='all'), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b39b6",
   "metadata": {},
   "source": [
    "### Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loan_dev_df[loan_dev_df['status'] == 1]) / len(loan_dev_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bffac",
   "metadata": {},
   "source": [
    "Around 86% of loans in the dataset have been payed off, so accuracy is not the best measure to optimize for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d435a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_values = loan_dev_df[\"status\"].value_counts()\n",
    "plt.title(\"Was the loan given?\")\n",
    "plt.bar([\"yes\", \"no\"], status_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a8eae3",
   "metadata": {},
   "source": [
    "This bar plot shows the number of loans given and the number of loans not given side by side. From this graph, you can understand that, for most cases, the loan was given. Therefore, this can be considered and unbalanced dataset, making it harder to predict when loans are not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.violinplot(x='status', y='amount', data=loan_dev_df, hue='status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e77896",
   "metadata": {},
   "source": [
    "We can see a larger amount of the loans over 100,000 are not payed off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cff7c1",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872a7dd",
   "metadata": {},
   "source": [
    "## Whitespace Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.rename(columns=lambda x: x.strip(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de9b061",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621fb2ba",
   "metadata": {},
   "source": [
    "### Acount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dabfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658737de",
   "metadata": {},
   "source": [
    "No missing values on **account_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0fc54",
   "metadata": {},
   "source": [
    "### Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a489f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc9910",
   "metadata": {},
   "source": [
    "No missing values on **client_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f132f47",
   "metadata": {},
   "source": [
    "### Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604bab8",
   "metadata": {},
   "source": [
    "No missing values on **loan_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a883a",
   "metadata": {},
   "source": [
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb13ea7",
   "metadata": {},
   "source": [
    "There are missing values on **trans_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8547af9",
   "metadata": {},
   "source": [
    "#### Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146488ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trans_dev_df[trans_dev_df['operation'].isnull()]) / len(trans_dev_df['operation']) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea626bc",
   "metadata": {},
   "source": [
    "There is a significant number of null values in the operations column. These will be replaced by 'N/A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319834df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a7072",
   "metadata": {},
   "source": [
    "#### K Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40416d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04ffb5",
   "metadata": {},
   "source": [
    "There are many empty string values. It is assumed these mean the transaction type wasn't registered and they will be treated the same as null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227136db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_values_k_symbol(k):\n",
    "    if isinstance(k, float):\n",
    "        return'N/A'\n",
    "    elif isinstance(k, str) and k.strip() == '':\n",
    "        return 'N/A'\n",
    "    else:\n",
    "        return k\n",
    "\n",
    "trans_dev_df['k_symbol'] = trans_dev_df['k_symbol'].apply(remove_empty_values_k_symbol)\n",
    "\n",
    "trans_dev_df['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9fb775",
   "metadata": {},
   "source": [
    "#### Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabff64f",
   "metadata": {},
   "source": [
    "There aren't any empty strings. Null values will be replaced by unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a73363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['bank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac452db3",
   "metadata": {},
   "source": [
    "#### Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100f80b",
   "metadata": {},
   "source": [
    "There are many transactions to an account **0**. This will be treated as a transaction to an unknown account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db79109",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0929f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_dev_df['account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbf6d8",
   "metadata": {},
   "source": [
    "### Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5dd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_dev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c04f77",
   "metadata": {},
   "source": [
    "There are no missing values in **card_dev_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d443a",
   "metadata": {},
   "source": [
    "### Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60b69a",
   "metadata": {},
   "source": [
    "There are no missing values in **disp_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243df78",
   "metadata": {},
   "source": [
    "### District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc72143",
   "metadata": {},
   "source": [
    "There are missing values in **district_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df[district_df['unemploymant rate \\'95'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab2484",
   "metadata": {},
   "source": [
    "Both null values com from the district of Jesenik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454aab6c",
   "metadata": {},
   "source": [
    "We will replace the null values by finding the mean values for the region in 1995 and 1996 and inferring the 1995 values for Jesenik from the 1996 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1646876",
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_rate_96_mean = district_df[district_df['region'] == 'north Moravia']['unemploymant rate \\'96'].median()\n",
    "\n",
    "unemp_rate_95_mean = district_df[district_df['region'] == 'north Moravia']['unemploymant rate \\'95'].median()\n",
    "\n",
    "unemp_rate_96_jes = district_df.iloc[68]['unemploymant rate \\'96']\n",
    "\n",
    "predicted_unemp_rate_95_jes = (unemp_rate_95_mean/unemp_rate_96_mean) * unemp_rate_96_jes\n",
    "\n",
    "district_df['unemploymant rate \\'95'].fillna(predicted_unemp_rate_95_jes, inplace=True)\n",
    "\n",
    "crimes_96_mean = district_df[district_df['region'] == 'north Moravia']['no. of commited crimes \\'96'].median()\n",
    "\n",
    "crimes_95_mean = district_df[district_df['region'] == 'north Moravia']['no. of commited crimes \\'95'].median()\n",
    "\n",
    "crimes_96_jes = district_df.iloc[68]['no. of commited crimes \\'96']\n",
    "\n",
    "predicted_crimes_95_jes = (crimes_95_mean/crimes_96_mean) * crimes_96_jes\n",
    "\n",
    "district_df['no. of commited crimes \\'95'].fillna(predicted_crimes_95_jes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845097b1",
   "metadata": {},
   "source": [
    "## Date Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format birth number to date (DD-MM-YY) <- may need to change formatting for algorithms\n",
    "def get_formatted_date(date_number):\n",
    "    date_number_string = str(date_number)\n",
    "    return date_number_string[4:6] + '/' + str(int(date_number_string[2:4]) % 50) + '/' + '19' + date_number_string[0:2]\n",
    "\n",
    "# Get client sex from birth number (MM > 50 => sex == 'F')\n",
    "def get_client_sex_from_birth_number(date_number):\n",
    "    return 'F' if int(str(date_number)[2:4]) >= 51 else 'M'\n",
    "\n",
    "def get_season_from_Date(date_string):\n",
    "    date_string_str = str(date_string)\n",
    "    day = int(date_string_str[8:10])\n",
    "    month = int(date_string_str[5:7])\n",
    "    year = int(date_string_str[0:4])\n",
    "\n",
    "    winterStart = datetime.datetime(year, 12, 22)\n",
    "    springStart = datetime.datetime(year, 3, 20)\n",
    "    summerStart = datetime.datetime(year, 6, 21)\n",
    "    autumnStart = datetime.datetime(year, 9, 22)\n",
    "\n",
    "    if ((month <= 3 and day <= 20) or (month >= 12 and day > 22)):\n",
    "        return \"winter\"\n",
    "    elif (date_string < summerStart):\n",
    "        return \"spring\"\n",
    "    elif (date_string < autumnStart) : \n",
    "        return \"summer\"\n",
    "    elif (date_string < winterStart) :\n",
    "        return \"autumn\"\n",
    "\n",
    "    return \"FAILEDSEASON\"\n",
    "\n",
    "def get_year_from_date(date_string):\n",
    "    date_string_str = str(date_string)\n",
    "    year = int(date_string_str[0:4])\n",
    "\n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60dafe",
   "metadata": {},
   "source": [
    "## Format dates and determine client sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format client birthday and determine sex\n",
    "\n",
    "client_df['birthday'] = pd.to_datetime(client_df['birth_number'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "client_df['sex'] = client_df['birth_number'].apply(get_client_sex_from_birth_number)\n",
    "\n",
    "client_df = client_df.drop(columns=['birth_number'])\n",
    "\n",
    "# Format other dates\n",
    "\n",
    "account_df['acc_creation_date'] = pd.to_datetime(account_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "account_df = account_df.drop(columns=['date'])\n",
    "\n",
    "trans_dev_df['trans_date'] = pd.to_datetime(trans_dev_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "trans_dev_df = trans_dev_df.drop(columns=['date'])\n",
    "\n",
    "loan_dev_df['date'] = pd.to_datetime(loan_dev_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "card_dev_df['issued'] = pd.to_datetime(card_dev_df['issued'].apply(get_formatted_date), infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275a899",
   "metadata": {},
   "source": [
    "# Join Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2ea80",
   "metadata": {},
   "source": [
    "Data must all be displayed in one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb260c",
   "metadata": {},
   "source": [
    "## Join Account and Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = account_df.merge(disp_df, on='account_id', how='inner', suffixes=['', '_disp'])\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'type': 'account_type',\n",
    "    'frequency': 'issuance_freq'\n",
    "}, inplace=True)\n",
    "\n",
    "# Determine if account is shared or not\n",
    "owner_number_account = joined_df['account_id'].value_counts()\n",
    "\n",
    "joined_df['shared'] = joined_df.apply(lambda row: 1 if owner_number_account[row['account_id']] > 1 else 0, axis=1)\n",
    "\n",
    "# Drop rows with disponents so there are no duplicated account rows\n",
    "joined_df.drop(joined_df[joined_df['account_type'] == 'DISPONENT'].index, inplace=True)\n",
    "\n",
    "# Drop account_type and disp_id column\n",
    "joined_df.drop(columns=['account_type'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e16e6",
   "metadata": {},
   "source": [
    "## Join Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(client_df, on='client_id', how='left', suffixes=['', '_client'])\n",
    "\n",
    "joined_df.drop(columns=['client_id'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9cfbd",
   "metadata": {},
   "source": [
    "## Join District"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d613f10",
   "metadata": {},
   "source": [
    "There are currently two District ids in the dataset for each row. We are going to join on the client's district id since we surmise this information will be more relevant to wheter they pay off the loan or not than the district the account was registered on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbae4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(district_df, left_on='district_id_client', right_on='code', how='inner', suffixes=['', '_district'])\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'code': 'district_code',\n",
    "    'name': 'district_name'\n",
    "}, inplace=True)\n",
    "\n",
    "joined_df.drop(columns=['district_id', 'district_id_client'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e1e50",
   "metadata": {},
   "source": [
    "## Join Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50a234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.merge(loan_dev_df, on='account_id', how='right', suffixes=['', '_loan'])\n",
    "\n",
    "joined_df.rename(columns={\n",
    "    'date': 'loan_date'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add seasons\n",
    "joined_df['season_on_loan'] = joined_df['loan_date'].apply(get_season_from_Date)\n",
    "joined_df['loan_year'] = joined_df['loan_date'].apply(get_year_from_date)\n",
    "\n",
    "joined_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbedc9",
   "metadata": {},
   "source": [
    "## Determine account owner age on loan request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['age_on_loan_request'] = joined_df.apply(lambda row: (row['loan_date'] - row['birthday'])/np.timedelta64(1, 'Y'), axis=1)\n",
    "\n",
    "joined_df.drop(columns=['birthday'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5217a",
   "metadata": {},
   "source": [
    "## Join Cards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00e278",
   "metadata": {},
   "source": [
    "There are a lot of clients without cards so simply joining the datasets would result in a large amount of null values. Instead we will record the card score attached to each account giving more weight to *classic* and *gold* cards. This is done beacause to have access to better credit cards the client must have a history of making and paying of loans in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_disp_df = card_dev_df.merge(disp_df, on='disp_id', how='inner', suffixes=['_card', '_disp'])\n",
    "\n",
    "cards_per_user_df = card_disp_df.groupby(['account_id', 'type_card']).size().unstack(fill_value=0)\n",
    "\n",
    "joined_df = joined_df.merge(cards_per_user_df, on='account_id', how='left', suffixes=['', ''])\n",
    "\n",
    "joined_df.fillna(0, inplace=True)\n",
    "\n",
    "joined_df['card_score'] = (joined_df['junior'] + joined_df['classic'] * 3 + joined_df['gold'] * 10).astype(int)\n",
    "\n",
    "joined_df.drop(columns=['junior', 'classic', 'gold'], inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961cce3",
   "metadata": {},
   "source": [
    "## Join Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12db79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "account_balance_df = trans_dev_df[['account_id', 'balance', 'trans_date']]\n",
    "\n",
    "def find_balance_at_date(joined_df_row):\n",
    "    # Get all balance information for account\n",
    "    account_balances = account_balance_df[account_balance_df['account_id'] == joined_df_row['account_id']]\n",
    "\n",
    "    if (account_balances.empty):\n",
    "        joined_df_row['balance_at_loan'] = 0\n",
    "        joined_df_row['balance_three_months_before'] = 0\n",
    "        joined_df_row['balance_six_months_before'] = 0\n",
    "\n",
    "        return joined_df_row[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']]\n",
    "    \n",
    "    # Get balance at loan date\n",
    "    account_balances_at_loan_date = account_balances.copy()\n",
    "\n",
    "    account_balances_at_loan_date['days_since_trans'] = account_balances_at_loan_date.apply(lambda row: (joined_df_row['loan_date'] - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_at_loan_date = account_balances_at_loan_date[account_balances_at_loan_date['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_at_loan_date = account_balances_at_loan_date[account_balances_at_loan_date['days_since_trans'] == account_balances_at_loan_date['days_since_trans'].min()]\n",
    "\n",
    "\n",
    "    # Get balance three months before loan date\n",
    "    three_months_ago = joined_df_row['loan_date'] - relativedelta(months=3)\n",
    "\n",
    "    account_balances_three_months_ago = account_balances.copy()\n",
    "\n",
    "    account_balances_three_months_ago['days_since_trans'] = account_balances_three_months_ago.apply(lambda row: (three_months_ago - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_three_months_ago = account_balances_three_months_ago[account_balances_three_months_ago['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_three_months_ago = account_balances_three_months_ago[account_balances_three_months_ago['days_since_trans'] == account_balances_three_months_ago['days_since_trans'].min()]\n",
    "\n",
    "    # Get balance six months before loan date\n",
    "    six_months_ago = joined_df_row['loan_date'] - relativedelta(months=6)\n",
    "\n",
    "    account_balances_six_months_ago = account_balances.copy()\n",
    "\n",
    "    account_balances_six_months_ago['days_since_trans'] = account_balances_six_months_ago.apply(lambda row: (six_months_ago - row['trans_date']), axis=1)\n",
    "\n",
    "    account_balances_six_months_ago = account_balances_six_months_ago[account_balances_six_months_ago['days_since_trans'] >= pd.Timedelta(0)]\n",
    "\n",
    "    account_balances_six_months_ago = account_balances_six_months_ago[account_balances_six_months_ago['days_since_trans'] == account_balances_six_months_ago['days_since_trans'].min()]\n",
    "\n",
    "\n",
    "    joined_df_row['balance_at_loan'] = account_balances_at_loan_date.iloc[0]['balance'] if len(account_balances_at_loan_date.index) >= 1 else 0\n",
    "    joined_df_row['balance_three_months_before'] = account_balances_three_months_ago.iloc[0]['balance'] if len(account_balances_three_months_ago.index) >= 1 else 0\n",
    "    joined_df_row['balance_six_months_before'] = account_balances_six_months_ago.iloc[0]['balance'] if len(account_balances_six_months_ago.index) >= 1 else 0\n",
    "\n",
    "    return joined_df_row[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']]\n",
    "\n",
    "joined_df[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']] = joined_df.apply(find_balance_at_date, axis=1)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b687fbc",
   "metadata": {},
   "source": [
    "# Total interest accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96262d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = trans_dev_df.groupby(\"account_id\")\n",
    "account_balance_df = trans_dev_df[['account_id', 'k_symbol', 'amount']]\n",
    "\n",
    "interst_mean_df = pd.DataFrame(columns=[\"account_id\", \"interest_mean\"])\n",
    "\n",
    "\n",
    "for acc_id, group in grouped:\n",
    "    interst_mean = abs(group[group[\"k_symbol\"] == \"interest credited\"][\"amount\"].mean())\n",
    "    interst_mean_df = interst_mean_df.append({\"account_id\": int(acc_id), \"interest_mean\": interst_mean}, ignore_index=True)\n",
    "\n",
    "joined_df[\"interest_mean\"] = interst_mean_df[\"interest_mean\"]\n",
    "joined_df[\"interest_mean\"].fillna(0.0, inplace=True)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd33a1d",
   "metadata": {},
   "source": [
    "# Number of times balance droped below 5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e44190",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_balance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance_below_5k(joined_df_row):\n",
    "    # Get all balance information for account\n",
    "    account_balances = trans_dev_df[['account_id', 'balance', 'trans_date']][account_balance_df['account_id'] == joined_df_row['account_id']]\n",
    "\n",
    "    if (account_balances.empty):\n",
    "        joined_df_row['balance_below_5k'] = 0\n",
    "\n",
    "        return joined_df_row[['balance_below_5k']]\n",
    "    \n",
    "    # Get balance at loan date\n",
    "    account_balances_below_5k = account_balances.copy()\n",
    "\n",
    "    account_balances_below_5k = account_balances_below_5k[account_balances_below_5k['balance'] < 5000]\n",
    "\n",
    "    joined_df_row['balance_below_5k'] = account_balances_below_5k['balance'].count()\n",
    "\n",
    "    return joined_df_row[['balance_below_5k']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[['balance_below_5k']] = joined_df.apply(get_balance_below_5k, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea36296",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfdf3d",
   "metadata": {},
   "source": [
    "# Loan Amount / Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loan_amount_over_balance(row):\n",
    "    return row['amount'] / row['balance_at_loan'] if row['balance_at_loan'] > 0 else -1\n",
    "\n",
    "joined_df['loan_amount_over_balance'] = joined_df.apply(get_loan_amount_over_balance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea709f3",
   "metadata": {},
   "source": [
    "### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.displot(joined_df, x=\"age_on_loan_request\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106077c",
   "metadata": {},
   "source": [
    "This is a distribution of the age of the client at the time they asked for the loan. From this image, we can conclude that most people apply for a loan when they are 30-40 years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfff3ef",
   "metadata": {},
   "source": [
    "### 3D Scatter Plot\n",
    "For these graphs, if it's green, it means that the loan was given and if it's red, it means that the loan was not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = joined_df['amount']\n",
    "x = joined_df['payments']\n",
    "\n",
    "colors = ['g' if s == 1 else 'r' for s in joined_df['status']]\n",
    "plt.ylabel('Loan amount')\n",
    "plt.xlabel('Payment')\n",
    "plt.scatter(x, ys, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8806b",
   "metadata": {},
   "source": [
    "This scatter plot shows the payment and the loan amount (besides the status). We can then conclude that the bigger the payment, the bigger the amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77bf28",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1141782",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.describe()[['no. of commited crimes \\'95', 'age_on_loan_request', 'duration', 'payments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216db2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(joined_df, x='no. of commited crimes \\'95')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_IQR(df):\n",
    "\n",
    "   q1=df.quantile(0.25)\n",
    "\n",
    "   q3=df.quantile(0.75)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "\n",
    "   return outliers\n",
    "\n",
    "outliers = find_outliers_IQR(joined_df['no. of commited crimes \\'95'])\n",
    "\n",
    "print(\"number of outliers: \" + str(len(outliers)))\n",
    "\n",
    "print(\"max outlier value: \" + str(outliers.max()))\n",
    "\n",
    "print(\"min outlier value: \" + str(outliers.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b0a20",
   "metadata": {},
   "source": [
    "### Remove underage users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2de0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "underage = joined_df.loc[joined_df['age_on_loan_request']<18]\n",
    "\n",
    "joined_df.drop(underage.index, inplace=True)\n",
    "\n",
    "joined_df.describe()[['age_on_loan_request']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e776f",
   "metadata": {},
   "source": [
    "# Split into age brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd931db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(joined_df, x='age_on_loan_request')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_bracket(age):\n",
    "    if age >= 18 and age <= 24:\n",
    "        return '18-24'\n",
    "    elif age >= 25 and age <= 34:\n",
    "        return '25-34'\n",
    "    elif age>= 35 and age <= 44:\n",
    "        return '35-44'\n",
    "    elif age >= 45 and age <= 54:\n",
    "        return '45-54'\n",
    "    elif age >= 55 and age <= 64:\n",
    "        return '55-64'\n",
    "    elif age >= 65:\n",
    "        return '65+'\n",
    "\n",
    "joined_df['age_bracket'] = joined_df['age_on_loan_request'].apply(get_age_bracket)\n",
    "\n",
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8bb4b",
   "metadata": {},
   "source": [
    "## Set Correct Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['shared'] = joined_df['shared'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['status'] = joined_df['status'].apply(lambda x: 1 if x == -1 else 0)\n",
    "joined_df['status'] = joined_df['status'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad78fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop(columns=['district_name', 'account_id', 'disp_id', 'age_on_loan_request'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add662f",
   "metadata": {},
   "source": [
    "### Remove Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25064b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['sex', 'region', 'issuance_freq', 'season_on_loan', 'age_bracket']\n",
    "\n",
    "joined_df[cat] = joined_df[cat].astype('category')\n",
    "\n",
    "joined_df[cat] = joined_df[cat].apply(lambda x : x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470174f5",
   "metadata": {},
   "source": [
    "# Clustering - Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf397b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2dbb6",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8912882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joined_df.drop(['status'], axis=1)\n",
    "X.drop(columns=['acc_creation_date', 'loan_date'], inplace=True)\n",
    "y = joined_df['status']\n",
    "\n",
    "X = StandardScaler().fit_transform(X, y)\n",
    "X = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "wss = []\n",
    "silhouette = []\n",
    "\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wss.append(kmeans.inertia_)\n",
    "    silhouette.append(metrics.silhouette_score(X, kmeans.labels_))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(range(2, 10), silhouette)\n",
    "ax[1].plot(range(2, 10), wss)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "ax[0].set_title('Silhouette method')\n",
    "ax[1].set_title('Elbow curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d239e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joined_df.drop(['status'], axis=1)\n",
    "X.drop(columns=['acc_creation_date', 'loan_date'], inplace=True)\n",
    "y = joined_df['status']\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "db = KMeans(n_clusters=3, random_state=42).fit_predict(X)\n",
    "\n",
    "# Plot result\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "axs[0].scatter(X[:, 0], X[:, 1], c=db)\n",
    "\n",
    "scatter = axs[1].scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "axs[0].set_title(\"Kmeans\")\n",
    "axs[1].set_title(\"Status\")\n",
    "\n",
    "axs[1].legend(handles=scatter.legend_elements()[0], labels=[-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0098b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster as cluster\n",
    "import seaborn as sns\n",
    "kmeans = cluster.KMeans(n_clusters=4, random_state=42)\n",
    "X=joined_df.drop(['status'],axis=1)\n",
    "X.drop(columns=['acc_creation_date', 'loan_date'], inplace=True)\n",
    "y = joined_df[\"status\"]\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(data = X, columns = ['principal component 1', 'principal component 2'])\n",
    "kmeans = kmeans.fit(pca_df)\n",
    "\n",
    "pca_df['Clusters'] = kmeans.labels_\n",
    "\n",
    "sns.scatterplot(x=\"principal component 1\", y=\"principal component 2\",hue = 'Clusters',  data=pca_df,palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa91567",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'shared',\n",
    "    'no. of municipalities with inhabitants < 499',\n",
    "    'no. of municipalities with inhabitants 500-1999',\n",
    "    'no. of municipalities with inhabitants 2000-9999',\n",
    "    'no. of municipalities with inhabitants >10000', \n",
    "    'no. of cities',\n",
    "    'ratio of urban inhabitants', \n",
    "    'average salary', \n",
    "    'unemploymant rate \\'96', \n",
    "    'no. of enterpreneurs per 1000 inhabitants',\n",
    "    'amount', \n",
    "    'duration', \n",
    "    'payments',\n",
    "    'age_bracket',\n",
    "    'card_score', \n",
    "    'balance_at_loan',\n",
    "    'balance_three_months_before',\n",
    "    'balance_six_months_before',\n",
    "    'issuance_freq',\n",
    "    'sex', \n",
    "    'district_code',\n",
    "    'region',\n",
    "    'season_on_loan',\n",
    "    'loan_year',\n",
    "    'interest_mean',\n",
    "    'balance_below_5k',\n",
    "    'loan_amount_over_balance'\n",
    "    ]\n",
    "    \n",
    "target = 'status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[features][joined_df['number_of_payed_off_prev_loans'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = joined_df[features + [target]].corr(method='spearman')\n",
    "\n",
    "mask = np.zeros_like(corr_matrix, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.title('Correlation Matrix', fontsize=25)\n",
    "_ = sb.heatmap(corr_matrix, mask=mask, cmap='coolwarm', annot=True, fmt='.2f', linewidths=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a94fc",
   "metadata": {},
   "source": [
    "### VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752386be",
   "metadata": {},
   "source": [
    "We are going to test for VIF to check for multicolinearity between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load statmodels functions\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# compute the vif for all given features\n",
    "def compute_vif(considered_features):\n",
    "    \n",
    "    X = joined_df[considered_features].copy()\n",
    "    # the calculation of variance inflation requires a constant\n",
    "    X['intercept'] = 1\n",
    "    \n",
    "    # create dataframe to store vif values\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "    vif = vif[vif['Variable']!='intercept']\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e8bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    'no. of municipalities with inhabitants < 499',\n",
    "    'no. of municipalities with inhabitants 500-1999',\n",
    "    'no. of municipalities with inhabitants 2000-9999',\n",
    "    'no. of municipalities with inhabitants >10000', \n",
    "    'no. of cities',\n",
    "    'ratio of urban inhabitants', \n",
    "    'average salary', \n",
    "    'unemploymant rate \\'96', \n",
    "    'no. of enterpreneurs per 1000 inhabitants',\n",
    "    'amount', \n",
    "    'duration', \n",
    "    'payments',\n",
    "    'card_score', \n",
    "    'balance_at_loan',\n",
    "    'balance_three_months_before',\n",
    "    'balance_six_months_before',\n",
    "    'loan_year',\n",
    "    'interest_mean',\n",
    "    'balance_below_5k',\n",
    "    'loan_amount_over_balance'\n",
    "    ]\n",
    "\n",
    "vif = compute_vif(numeric_features).sort_values(by='VIF', ascending=False)\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c40ba",
   "metadata": {},
   "source": [
    "VIF threshhold at 5. removing amount and recalculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features.remove('amount')\n",
    "\n",
    "vif = compute_vif(numeric_features).sort_values(by='VIF', ascending=False)\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952ef55",
   "metadata": {},
   "source": [
    "VIF on payments improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaa405",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features.remove('average salary')\n",
    "\n",
    "vif = compute_vif(numeric_features).sort_values(by='VIF', ascending=False)\n",
    "\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb7f6c",
   "metadata": {},
   "source": [
    "All VIF values in threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('average salary')\n",
    "features.remove('amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384edecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2)\n",
    "fig.set_size_inches(15, 10)\n",
    "sb.countplot(x=\"season_on_loan\", data=joined_df[joined_df[\"status\"] == 1], ax=ax[0][0])\n",
    "sb.countplot(x=\"season_on_loan\", data=joined_df[joined_df[\"status\"] != 1], ax=ax[0][1])\n",
    "sb.violinplot(x=\"season_on_loan\", y=\"amount\", data=joined_df, hue=\"status\", ax=ax[1][0])\n",
    "sb.violinplot(x=\"season_on_loan\", y=\"duration\", data=joined_df, hue=\"status\", ax=ax[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6a611",
   "metadata": {},
   "source": [
    "Throughout the year the amount of accepted loans is descreasing. We can also notice in autumn the lower bound of loans are higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e22dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.columns)\n",
    "# sb.lineplot(x=\"age_on_loan_request\", y=\"balance_at_loan\", data=joined_df)\n",
    "# sb.displot(x=\"age_on_loan_request\", data=joined_df, kde=True, hue=\"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c642ed3",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d597bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "def do_anova(cols, k=\"all\"):\n",
    "    best_features = SelectKBest(score_func=f_classif, k=k)\n",
    "    df_cut = joined_df[cols]\n",
    "    fit = best_features.fit(df_cut, joined_df[\"status\"])\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(df_cut.columns)\n",
    "\n",
    "    # concat 2 dataFrame for better visualization\n",
    "    feature_score = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    feature_score.columns = [\"Features\", \"Score\"]\n",
    "    ret = feature_score.sort_values(by=\"Score\", ascending=False)\n",
    "    return ret.head(k) if k != \"all\" else ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf78fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_anova(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'shared',\n",
    "    'balance_at_loan',\n",
    "    'payments',\n",
    "    'balance_six_months_before',\n",
    "    'balance_three_months_before',\n",
    "    'season_on_loan',\n",
    "    'age_bracket',\n",
    "    'loan_year',\n",
    "    'interest_mean',\n",
    "    'balance_below_5k',\n",
    "    'loan_amount_over_balance',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d1a1f",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace7cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68af59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joined_df[selected_features]\n",
    "y = joined_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3578526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # 70% training and 30% test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92998bf2",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Some of the algorithms we plan on using (KNN and SVM) require the data to be standardized. To do so, we used a StandardScaler from SciKit Learn's preprocessing library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30978fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sk.preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361601b6",
   "metadata": {},
   "source": [
    "## Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad928ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Decision Tree classifer object\n",
    "# clf = DecisionTreeClassifier(min_samples_leaf=15, max_depth=5)\n",
    "\n",
    "# # Train Decision Tree Classifer\n",
    "# clf = clf.fit(X_train,y_train)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba = clf.predict_proba(X_test)\n",
    "# print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "# print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# display = PrecisionRecallDisplay.from_estimator(\n",
    "#     clf, X_test, y_test, name=\"DecisionTree\"\n",
    "# )\n",
    "# _ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "# cm_display.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "\n",
    "# fig = plt.figure(figsize=(25,20))\n",
    "# _ = tree.plot_tree(clf, \n",
    "#                    feature_names=selected_features,  \n",
    "#                    class_names=target,\n",
    "#                    filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db072a0",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# # lsvc = SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0, decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
    "# #  max_iter=-1, probability=True, random_state=1234, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "# lsvc = SVC(verbose=0, C=0.01, kernel='poly')\n",
    "\n",
    "# lsvc.fit(X_train, y_train)\n",
    "# y_pred = lsvc.predict(X_test)\n",
    "\n",
    "# score = lsvc.score(X_train, y_train)\n",
    "# print(score)\n",
    "# print(\"REcall: \", metrics.recall_score(y_test, y_pred))\n",
    "# print(\"Precison: \", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# display = PrecisionRecallDisplay.from_estimator(\n",
    "#     lsvc, X_test, y_test, name=\"SVC\"\n",
    "# )\n",
    "# _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba = clf.predict_proba(X_test)\n",
    "# print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "# cm_display.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e2561",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "# logisticRegr = LogisticRegression(C=0.01, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1,\n",
    "#  l1_ratio=None, max_iter=1000, multi_class='multinomial', n_jobs=None, penalty='l2', random_state=1234, solver='newton-cg',\n",
    "#   tol=0.0001, verbose=0, warm_start=False)\n",
    "# #multi_class : 'auto', 'ovr', 'multinomial'\n",
    "# # solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default='lbfgs'\n",
    "# logisticRegr.fit(X_train, y_train)\n",
    "# y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "# score = logisticRegr.score(X_train, y_train)\n",
    "# print(score)\n",
    "# print(\"REcall: \", metrics.recall_score(y_test, y_pred))\n",
    "# print(\"Precison: \", metrics.precision_score(y_test, y_pred))\n",
    "# print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# display = PrecisionRecallDisplay.from_estimator(\n",
    "#     logisticRegr, X_test, y_test, name=\"LogisticRegression\"\n",
    "# )\n",
    "# _ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "\n",
    "# NOT SURE HOW IT WORKS\n",
    "\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# scoring = {\"accuracy\": \"accuracy\",\n",
    "#            \"precision\": \"precision\",\n",
    "#            \"recall\": \"recall\",\n",
    "#            \"f1\": \"f1\",\n",
    "#            \"roc_auc\": \"roc_auc\"}\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# k = 5\n",
    "# kr = 3\n",
    "# kf = RepeatedStratifiedKFold(n_splits=k, n_repeats=kr, random_state=0)\n",
    "# info = cross_validate(logisticRegr, X_train, y_train, scoring=scoring, cv=kf, n_jobs=-1)\n",
    "# pd.DataFrame(info).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba = clf.predict_proba(X_test)\n",
    "# print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "# cm_display.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f190d3",
   "metadata": {},
   "source": [
    "## LGBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "# from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "# lgbm = LGBMClassifier(objective='binary', random_state=0)\n",
    "# # lgbm = LGBMClassifier(task = 'train', objective='binary', num_classes = 1, random_state=0, learning_rate = 0.0005, num_iterations = 10000)\n",
    "# # 'task': 'train',\n",
    "# #     'boosting_type': 'gbdt',\n",
    "# #     'objective': 'multiclass',\n",
    "# #     'num_class':3,\n",
    "# #     'metric': 'multi_logloss',\n",
    "# #     'learning_rate': 0.002296,\n",
    "# #     'max_depth': 7,\n",
    "# #     'num_leaves': 17,\n",
    "# #     'feature_fraction': 0.4,\n",
    "# #     'bagging_fraction': 0.6,\n",
    "# #     'bagging_freq': 17\n",
    "# lgbm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# y_pred = lgbm.predict(X_test)   \n",
    "# # lgbm.f1\n",
    "# score = lgbm.score(X_train, y_train)\n",
    "# print(score)\n",
    "# print(\"REcall: \", metrics.recall_score(y_test, y_pred))\n",
    "# print(\"Precison: \", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# display = PrecisionRecallDisplay.from_estimator(\n",
    "#     lgbm, X_test, y_test, name=\"LGBM\"\n",
    "# )\n",
    "# _ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_proba = clf.predict_proba(X_test)\n",
    "# print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "# cm_display.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c79b68",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9876256",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62922d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state=1234)\n",
    "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df814d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39000ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=10, max_depth=5)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train_smote,y_train_smote)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a943b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f55d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(clf, \n",
    "                   feature_names=selected_features,  \n",
    "                   class_names=target,\n",
    "                   filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16edcb",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79024544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "lsvc = SVC(verbose=0, C=0.5, kernel='rbf', probability=True, random_state = 24)\n",
    "\n",
    "lsvc.fit(X_train_smote, y_train_smote)\n",
    "y_pred = lsvc.predict(X_test)\n",
    "\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    lsvc, X_test, y_test, name=\"LogisticRegression\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lsvc.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139eae21",
   "metadata": {},
   "source": [
    "## Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb92bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "# logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "logisticRegr = LogisticRegression(C=0.01, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1,\n",
    " l1_ratio=None, max_iter=1000, multi_class='multinomial', n_jobs=None, penalty='l2', random_state=1234, solver='saga',\n",
    "  tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "logisticRegr.fit(X_train_smote, y_train_smote)\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    logisticRegr, X_test, y_test, name=\"LogisticRegression\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegr.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e44bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b433bec",
   "metadata": {},
   "source": [
    "## LGBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d655715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "lgbm = LGBMClassifier(objective='binary', random_state=0)\n",
    "lgbm.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "\n",
    "y_pred = lgbm.predict(X_test)   \n",
    "\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    lgbm, X_test, y_test, name=\"LGBM\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d681ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lgbm.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04696702",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b795e5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = sk.neighbors.KNeighborsClassifier(\n",
    "    n_neighbors=50,\n",
    "    weights='distance',\n",
    "    algorithm='ball_tree',\n",
    "    leaf_size=1,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "knn.fit(X_train_smote, y_train_smote)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(sk.metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: \",sk.metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", sk.metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", sk.metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10094ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    knn, X_test, y_test, name=\"KNN\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b5982",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "X_train_comp = joined_df[selected_features]\n",
    "y_train_comp = joined_df[target]\n",
    "\n",
    "oversample = SMOTE(random_state=1234)\n",
    "X_train_smote_comp, y_train_smote_comp = oversample.fit_resample(X_train_comp, y_train_comp)\n",
    "\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tn_trees = [10, 50, 100, 500, 1000]\n",
    "\tfor n in n_trees:\n",
    "\t\t# explore number of features from 1 to 7\n",
    "\t\tfor i in range(1,len(selected_features) + 1):\n",
    "\t\t\t# explore ratios from 10% to 100% in 10% increments\n",
    "\t\t\tfor j in arange(0.1, 1.1, 0.1):\n",
    "\t\t\t\tkey = str(n) + ' ' + str(i) + ' ' + ('%.1f' % j)\n",
    "\t\t\t\t# set max_samples=None to use 100%\n",
    "\t\t\t\tif j == 1.0:\n",
    "\t\t\t\t\tj = None\n",
    "\t\t\t\tmodels[key] = RandomForestClassifier(max_samples=j, max_features=i, n_estimators=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "recall_results = {}\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train_smote_comp, y_train_smote_comp)\n",
    "\t# store the results\n",
    "\trecall_results[name] = mean(scores)\n",
    "\n",
    "\n",
    "best_model = max(recall_results, key=recall_results.get)\n",
    "print(best_model, recall_results[best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b560a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features=4, max_samples=1.0)\n",
    "\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "print(\"AUROC: \", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf01b36",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_svc():\n",
    "\tmodels = dict()\n",
    "\tfor i in ['rbf', 'linear', 'poly', 'sigmoid']:\n",
    "\t\t# explore ratios from 10% to 100% in 10% increments\n",
    "\t\tfor j in [0.01, 0.1, 0.5, 1.0]:\n",
    "\t\t\tkey = str(i) + ' ' + ('%.1f' % j)\n",
    "\t\t\t# set max_samples=None to use 100%\n",
    "\t\t\tmodels[key] = SVC(C=j, kernel=i, probability=True, random_state = 1234)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models_svc()\n",
    "# evaluate the models and store results\n",
    "recall_results = {}\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X_train_smote_comp, y_train_smote_comp)\n",
    "\t# store the results\n",
    "\trecall_results[name] = mean(scores)\n",
    "\n",
    "\n",
    "best_model = max(recall_results, key=recall_results.get)\n",
    "print(best_model, recall_results[best_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f6e8f",
   "metadata": {},
   "source": [
    "# Test 100 iterations of each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e5c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recallSum = {\"DecisionT\":0,\"SVC\":0,\"LogisticReg\":0,\"lgbm\":0,\"knn\":0,\"rf\":0}\n",
    "\n",
    "# for i in range(100):\n",
    "#     oversample = SMOTE()\n",
    "#     X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "#     clf = clf.fit(X_train_smote,y_train_smote)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     recallSum[\"DecisionT\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "#     lsvc.fit(X_train_smote, y_train_smote)\n",
    "#     y_pred = lsvc.predict(X_test)\n",
    "#     recallSum[\"SVC\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "#     logisticRegr.fit(X_train_smote, y_train_smote)\n",
    "#     y_pred = logisticRegr.predict(X_test)\n",
    "#     recallSum[\"LogisticReg\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "#     lgbm.fit(X_train_smote, y_train_smote)\n",
    "#     y_pred = lgbm.predict(X_test)   \n",
    "#     recallSum[\"lgbm\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "#     knn.fit(X_train_smote, y_train_smote)\n",
    "#     y_pred = knn.predict(X_test)\n",
    "#     recallSum[\"knn\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "#     rf.fit(X_train_smote, y_train_smote)\n",
    "#     y_pred = rf.predict(X_test)\n",
    "#     recallSum[\"rf\"] += metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "# for key in recallSum :\n",
    "#     print(\"Position - \"+  str(key) + \" -> \" + str(recallSum[key]/100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a04b9e5",
   "metadata": {},
   "source": [
    "# Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5507a",
   "metadata": {},
   "source": [
    "## Prepare competition data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357dc52",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19dcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\trans_comp.csv', sep=';', low_memory=False)\n",
    "\n",
    "loan_comp_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\loan_comp.csv', sep=';', low_memory=False)\n",
    "\n",
    "card_comp_df = pd.read_csv('.\\\\ficheiros_competicao_dev\\\\card_comp.csv', sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25de523",
   "metadata": {},
   "source": [
    "### Treat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1587f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp_df['operation'].fillna('N/A', inplace=True)\n",
    "trans_comp_df['k_symbol'] = trans_comp_df['k_symbol'].apply(remove_empty_values_k_symbol)\n",
    "trans_comp_df['bank'].fillna('Unknown', inplace=True)\n",
    "trans_comp_df['account'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_comp_df['trans_date'] = pd.to_datetime(trans_comp_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "trans_comp_df = trans_comp_df.drop(columns=['date'])\n",
    "\n",
    "loan_comp_df['date'] = pd.to_datetime(loan_comp_df['date'].apply(get_formatted_date), infer_datetime_format=True)\n",
    "\n",
    "card_comp_df['issued'] = pd.to_datetime(card_comp_df['issued'].apply(get_formatted_date), infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ead60",
   "metadata": {},
   "source": [
    "### Join Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e807e",
   "metadata": {},
   "source": [
    "#### Account and Disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00506822",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = account_df.merge(disp_df, on='account_id', how='inner', suffixes=['', '_disp'])\n",
    "\n",
    "comp_df.rename(columns={\n",
    "    'type': 'account_type',\n",
    "    'frequency': 'issuance_freq'\n",
    "}, inplace=True)\n",
    "\n",
    "# Determine if account is shared or not\n",
    "owner_number_account = comp_df['account_id'].value_counts()\n",
    "\n",
    "comp_df['shared'] = comp_df.apply(lambda row: 1 if owner_number_account[row['account_id']] > 1 else 0, axis=1)\n",
    "\n",
    "# Drop rows with disponents so there are no duplicated account rows\n",
    "comp_df.drop(comp_df[comp_df['account_type'] == 'DISPONENT'].index, inplace=True)\n",
    "\n",
    "# Drop account_type and disp_id column\n",
    "comp_df.drop(columns=['account_type'], inplace=True)\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a74a5e",
   "metadata": {},
   "source": [
    "##### Competition and Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = comp_df.merge(client_df, on='client_id', how='left', suffixes=['', '_client'])\n",
    "\n",
    "comp_df.drop(columns=['client_id'], inplace=True)\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167feba",
   "metadata": {},
   "source": [
    "#### Competition and District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = comp_df.merge(district_df, left_on='district_id_client', right_on='code', how='inner', suffixes=['', '_district'])\n",
    "\n",
    "comp_df.rename(columns={\n",
    "    'code': 'district_code',\n",
    "    'name': 'district_name'\n",
    "}, inplace=True)\n",
    "\n",
    "comp_df.drop(columns=['district_id', 'district_id_client'], inplace=True)\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed074d90",
   "metadata": {},
   "source": [
    "#### Competition and Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c97ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = comp_df.merge(loan_comp_df, on='account_id', how='right', suffixes=['', '_loan'])\n",
    "\n",
    "comp_df.rename(columns={\n",
    "    'date': 'loan_date'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add seasons\n",
    "comp_df['season_on_loan'] = comp_df['loan_date'].apply(get_year_from_date)\n",
    "\n",
    "comp_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['age_on_loan_request'] = comp_df.apply(lambda row: (row['loan_date'] - row['birthday'])/np.timedelta64(1, 'Y'), axis=1)\n",
    "\n",
    "comp_df.drop(columns=['birthday'], inplace=True)\n",
    "\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_disp_df = card_comp_df.merge(disp_df, on='disp_id', how='inner', suffixes=['_card', '_disp'])\n",
    "\n",
    "cards_per_user_df = card_disp_df.groupby(['account_id', 'type_card']).size().unstack(fill_value=0)\n",
    "\n",
    "comp_df = comp_df.merge(cards_per_user_df, on='account_id', how='left', suffixes=['', ''])\n",
    "\n",
    "comp_df.fillna(0, inplace=True)\n",
    "\n",
    "comp_df['card_score'] = (comp_df['junior'] + comp_df['classic'] * 3 + comp_df['gold'] * 10).astype(int)\n",
    "\n",
    "comp_df.drop(columns=['junior', 'classic', 'gold'], inplace=True)\n",
    "\n",
    "comp_df['loan_year'] = comp_df['loan_date'].apply(get_year_from_date)\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46ebb4",
   "metadata": {},
   "source": [
    "#### Competition and Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830be323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "account_balance_df = trans_comp_df[['account_id', 'balance', 'trans_date']]\n",
    "\n",
    "comp_df[['balance_at_loan', 'balance_three_months_before', 'balance_six_months_before']] = comp_df.apply(find_balance_at_date, axis=1)\n",
    "\n",
    "comp_df[\"interest_mean\"] = interst_mean_df[\"interest_mean\"]\n",
    "comp_df[\"interest_mean\"].fillna(0.0, inplace=True)\n",
    "\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc5ca8",
   "metadata": {},
   "source": [
    "#### Get age bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6703d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['age_bracket'] = comp_df['age_on_loan_request'].apply(get_age_bracket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b8d07",
   "metadata": {},
   "source": [
    "#### Set correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff986a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df['shared'] = comp_df['shared'].astype('bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df.drop(columns=['district_name', 'account_id', 'disp_id', 'age_on_loan_request'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b760c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['sex', 'region', 'issuance_freq', 'season_on_loan', 'age_bracket']\n",
    "\n",
    "comp_df[cat] = comp_df[cat].astype('category')\n",
    "\n",
    "comp_df[cat] = comp_df[cat].apply(lambda x : x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "X_train_comp = joined_df[selected_features]\n",
    "y_train_comp = joined_df[target]\n",
    "\n",
    "oversample = SMOTE(random_state=1234)\n",
    "X_train_smote_comp, y_train_smote_comp = oversample.fit_resample(X_train_comp, y_train_comp)\n",
    "\n",
    "lsvc = SVC(verbose=0, C=0.5, kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "lsvc.fit(X_train_smote_comp, y_train_smote_comp)\n",
    "\n",
    "score = lsvc.score(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca37de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_features=4, max_samples=1.0)\n",
    "\n",
    "rf.fit(X_train_smote_comp, y_train_smote_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c073633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = sk.neighbors.KNeighborsClassifier(\n",
    "#     n_neighbors=50,\n",
    "#     weights='distance',\n",
    "#     algorithm='ball_tree',\n",
    "#     leaf_size=1,\n",
    "#     n_jobs=-1\n",
    "#     )\n",
    "\n",
    "# knn.fit(X_train_smote_comp, y_train_smote_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df9a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_comp = comp_df[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = rf.predict_proba(X_test_comp)\n",
    "# print(\"Recall: \",sk.metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=['Id', 'Predicted'])\n",
    "\n",
    "res_df['Id'] = comp_df['loan_id'].copy()\n",
    "\n",
    "res_df['Predicted'] = y_pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9352b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('res.csv', sep=',', index=False, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6847c98a8f86b01c6a19c518cd2f366693b80566b266804d5ca763cbb223f52b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
